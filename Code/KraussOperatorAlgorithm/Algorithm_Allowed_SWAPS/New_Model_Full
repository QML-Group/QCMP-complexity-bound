import numpy as np
import networkx as nx
import scipy as sp

beta = 2
n=3
#The main change is the second test is that the IG and CG are now represented correctly. Moreover the pms[] set has also been automated. Furthermore the projects 
#for the 3 vertex model have been added these will still need to be automated once we have established the correct use of the projectors. 

#Functions for the preprocessing and importing of the graphs which we want to use.
#function which converts a Networkx graph to a Laplacian Matrix
def G_to_LM(x):
    LM = sp.sparse.csr_matrix.toarray(nx.laplacian_matrix(nx.from_numpy_matrix(x)))
    return LM
def G_to_LM_eig(x):
    LM = sp.sparse.csr_matrix.toarray(nx.laplacian_matrix(nx.from_numpy_matrix(x)))
    L = np.zeros((n,n))
    for i in range(n):
        L[i][i]=np.linalg.eig(LM)[0][i]
    return L
#function which converts a numpy array of a graph to a density matrix
def rho(x):
    rho = sp.linalg.expm(-beta*G_to_LM(x))/np.trace((sp.linalg.expm(-beta*G_to_LM_eig(x))))
    return rho
#function which determines the Von Neuman Entropy of a density matrix
def S(x):
    return -sum(np.linalg.eig(x)[0]*np.log2(np.linalg.eig(x)[0]))
#function which determines the Q_jsd for two given density matrices
def Q_jsd(x,y):
    sum_xy = (x+y)/2
    f = S(sum_xy)-(S(x)+S(y))/2
    return f

##Read in the set of graphs. This should be changed to the graphs which Median also uses. 
G2 = nx.read_graph6('/Users/s.b.szkudlarek/Documents/1 - Study/MSc/MSc Thesis/Code/Entropy sepctrum all + data/graph3.g6')
G2L = [None]*len(G2)
for i in range(len(G2)):
    G2L[i]=nx.to_numpy_array(G2[i])

#Assign the graphs to the CG and IG 
IG=G2L[3]
#CG = np.array([[0,1,0,0,0,0],[1,0,1,0,0,0],[0,1,0,1,0,0],[0,0,1,0,1,0],[0,0,0,1,0,1],[0,0,0,0,1,0]])
#IG = np.array([[0,1,0,0,0,1],[1,0,1,0,0,0],[0,1,0,1,0,0],[0,0,1,0,1,0],[0,0,0,1,0,1],[1,0,0,0,1,0]])
#CG=np.array([[0,0,1,0],[0,0,0,1],[1,0,0,1],[0,1,1,0]])
CG=G2L[2]
#CG=np.array([[0,1,1],[1,0,0],[1,0,0]])

#Define the projectors we want to use in the 3x3 model 
P1 =np.array([[1,0,0],[0,0,0],[0,0,0]])
P2 =np.array([[0,0,0],[0,1,0],[0,0,0]])
P3 =np.array([[0,0,0],[0,0,0],[0,0,1]])
P4 =np.array([[1,0,0],[0,1,0],[0,0,0]])
P5 =np.array([[0,0,0],[0,1,0],[0,0,1]])
P6 =np.array([[0,1,0],[1,0,0],[0,0,0]])
P7 =np.array([[0,0,0],[0,0,1],[0,1,0]])
P8 =np.array([[0,0,1],[0,0,0],[1,0,0]])

#Optimisation function & constraints
#generate the permutation matrices (PM)
#generate the permutation matrices (PM)
pms = []
for j in range(n):
    for i in range(n-j):
        if CG[j][i+j]==1:
            swap_allowed=np.identity(n)
            swap_allowed[i+j][i+j]=0
            swap_allowed[j][j]=0
            swap_allowed[i+j][j]=1
            swap_allowed[j][i+j]=1
            pms.append(swap_allowed)

#Define the function which we want to optimize 
def f(x):
    f = 0
    #define the krauss operator in terms of the PM and x
    #Make a second loop which allows for a SUM of Kraus operators. 
    sigma = np.zeros((n,n))
    sigma_E = np.zeros((n,n))
    for j in range(n):
        for i in range(n):
            sigma[j][i] = x[i+j*n]
    sigma_E = ((np.dot(np.dot(sigma,rho(CG)),sigma)))
        #sigma_proj = np.dot(np.dot(P1,sigma),P1)
    f = Q_jsd(sigma_E,rho(IG))+(np.trace(Kraus(x))-n)**2+(np.sum(Kraus(x)) - np.trace(Kraus(x)))**2+4*(np.array([np.sum(x)-1]))**2
    return f
#Check that the Kraus meet the constraint EE=1
def Kraus(x):
    rho = np.zeros((n,n))
    rho_E = np.zeros((n,n))
    for j in range(n):
        for i in range(n):
            rho[j][i] = x[i+j*n]
    rho_E = np.dot(rho,rho)
    return rho_E


#Format the constraints for Optimisation
def constraint1(x):
    return np.array([np.sum(x)-1])
def constraint2(x):
    return np.trace(Kraus(x))-n
def constraint3(x):
    off_dia_sum = np.sum(Kraus(x)) - np.trace(Kraus(x))
    return off_dia_sum - 1e-9
con1 = {'type': 'eq', 'fun': constraint1}
con2 = {'type': 'eq', 'fun': constraint2}
con3 = {'type': 'eq', 'fun': constraint3}
bounds = [(0,1)]
cons=[con2,con3]
options = {"maxiter": 5000}
#Optimize for the function f
#Generate a random set of theta's with a value between 0-1
x0 = np.random.uniform(0,1,n*n)
#x0=np.array([.1, .1, .1,.1,.1,.1])
#x0=np.ones((n*len(pms)))/(n*len(pms))
#x0 = np.array([0.98638881, 0.02834641, 0.46020884, 0.37974833, 0.84604831, 0.54845057])
#Preform the optimizatoion
sol = sp.optimize.minimize(f,x0,method='SLSQP',options=options)

#print the results in such a manner that they can be analysed
index = []
P = []
res = []
for i in range(n*n):
    res.append(sol.x[i])
    index.append(i)
for i in range(len(pms)):
    P.append(pms[i])
print(sol)
print(res)
print(x0)
print(P)
print(f(x0),Q_jsd(rho(IG),rho(CG)),sol.fun)
print(f(x0)-sol.fun,Q_jsd(rho(IG),rho(CG))-sol.fun)
print(Kraus(sol.x))